{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1ea9514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import koreanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "905d9250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./data/ratings_train.txt', sep=\"\\t\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4da2adf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        150000 non-null  int64 \n",
      " 1   document  149995 non-null  object\n",
      " 2   label     150000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bdf8825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 149995 entries, 0 to 149999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        149995 non-null  int64 \n",
      " 1   document  149995 non-null  object\n",
      " 2   label     149995 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.dropna()\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50cd0d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    75170\n",
       "1    74825\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c0f4e6",
   "metadata": {},
   "source": [
    "# 정규표현식을 사용한 텍스트 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "624a6205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8031e30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(x):\n",
    "    # 한글, 영문대소문자, 숫자만 남기고 모두 제거\n",
    "    cleaned = re.sub(r'[^가-힣a-zA-Z0-9]', \" \", x)\n",
    "    cleaned = cleaned.replace(\"  \", \" \").replace(\"  \", \" \").strip()\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7dbe2fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[:, 'document'] = train_df['document'].apply(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f3baff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df['document']\n",
    "y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4badf3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                         아 더빙 진짜 짜증나네요 목소리\n",
       "1                              흠 포스터보고 초딩영화줄 오버연기조차 가볍지 않구나\n",
       "2                                         너무재밓었다그래서보는것을추천한다\n",
       "3                                교도소 이야기구먼 솔직히 재미는 없다 평점 조정\n",
       "4         사이몬페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어보이기만 했던 커스틴 ...\n",
       "                                ...                        \n",
       "149995                                      인간이 문제지 소는 뭔죄인가\n",
       "149996                                           평점이 너무 낮아서\n",
       "149997                        이게 뭐요 한국인은 거들먹거리고 필리핀 혼혈은 착하다\n",
       "149998                          청춘 영화의 최고봉 방황과 우울했던 날들의 자화상\n",
       "149999                             한국 영화 최초로 수간하는 내용이 담긴 영화\n",
       "Name: document, Length: 149995, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e97aed78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         1\n",
       "2         0\n",
       "3         0\n",
       "4         1\n",
       "         ..\n",
       "149995    0\n",
       "149996    1\n",
       "149997    0\n",
       "149998    1\n",
       "149999    0\n",
       "Name: label, Length: 149995, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ad0938",
   "metadata": {},
   "source": [
    "# 훈련 데이터와 테스트 데이터로 분리 (홀드아웃)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "405b5c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "057df4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=10, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b9835b",
   "metadata": {},
   "source": [
    "# 문자를 벡터화 countvectorizer()\n",
    "- 모든 문자를 숫자로 변환해서 단어 사전을 만들어 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbf8a405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9adede3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = ['고양이가 나무 위에 있다', '나무 아래에 고양이가 있다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a07b846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['고양이가' '나무' '아래에' '위에' '있다']\n",
      "[[1 1 0 1 1]\n",
      " [1 1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "c_vec = CountVectorizer()\n",
    "x = c_vec.fit_transform(doc)\n",
    "print(c_vec.get_feature_names_out()) # 벡터화 된 단어 목록\n",
    "print(x.toarray()) # 단어의 빈도 벡터 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3436ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(X_train)\n",
    "X_train_cv = cv.transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b809e8",
   "metadata": {},
   "source": [
    "# 나이브베이즈로 감성분석 하기\n",
    "- MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9db33be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aaad38e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82     30068\n",
      "           1       0.83      0.80      0.82     29930\n",
      "\n",
      "    accuracy                           0.82     59998\n",
      "   macro avg       0.82      0.82      0.82     59998\n",
      "weighted avg       0.82      0.82      0.82     59998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_cv, y_train)\n",
    "pred = mnb.predict(X_test_cv)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b22bd9",
   "metadata": {},
   "source": [
    "# RandomForest와 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0077730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aca127c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77     30068\n",
      "           1       0.76      0.80      0.78     29930\n",
      "\n",
      "    accuracy                           0.77     59998\n",
      "   macro avg       0.78      0.77      0.77     59998\n",
      "weighted avg       0.78      0.77      0.77     59998\n",
      "\n",
      "CPU times: user 2h 44min 22s, sys: 7.13 s, total: 2h 44min 29s\n",
      "Wall time: 27min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rfc = RandomForestClassifier(n_estimators=300, n_jobs=6, random_state=10)\n",
    "rfc.fit(X_train_cv, y_train)\n",
    "pred2 = rfc.predict(X_test_cv)\n",
    "print(classification_report(y_test, pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784d9294",
   "metadata": {},
   "source": [
    "짱 오래 걸림"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca5ec0d",
   "metadata": {},
   "source": [
    "근데 CounterVectorizer는 띄어쓰기 기준 -> 한국어에는 적합하지는 않음 <br>\n",
    "한국어에는 조사가 있어서 형태소 분리를 해줘야 올바르게 분석할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b107a9f",
   "metadata": {},
   "source": [
    "# 한국어는 반드시 형태소 분석기로 형태소를 나눈 후 분석해야 한다.\n",
    "- morphs: 형태소를 분리해서 단어만 출력\n",
    "- pos: 형태소를 분리해서 단어와 형태소 종류를 튜플로 같이 출력\n",
    "- nouns: 형태소를 분리해서 명사만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214328c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mecab을 이용한 형태소 분리\n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f85abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"한국어는 반드시 형태소 분석기로 형태소를 나눈 후 분석해야 한다.\"\n",
    "print(mecab.morphs(text))\n",
    "print(mecab.nouns(text))\n",
    "print(mecab.pos(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f6a87f",
   "metadata": {},
   "source": [
    "# konlpy의 Mecab을 이용해 형태소 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d936c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    tokens = mecab.morphs(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7524a81",
   "metadata": {},
   "source": [
    "# CountVectorizer, TfidfVectorizer\n",
    "### 1) CountVectorizer: 단어 빈도(횟수) 기반 벡터화\n",
    "- 작동 방식: CountVectorizer는 각 문서에서 등장한 단어의 횟수(빈도)를 기준으로 벡터를 만듭니다. 단순히 각 문서에서 특정 단어가 몇 번 등장했는지를 세어 벡터화합니다.<br>\n",
    "- 특징:\n",
    "    - 각 단어의 빈도가 높을수록 해당 단어의 중요성이 더 크다고 가정합니다.<br>\n",
    "    - 빈도가 높다는 것만을 고려하기 때문에, 모든 문서에서 자주 등장하는 단어도 중요한 단어로 처리될 수 있습니다.<br>\n",
    "- 예시:<br>\n",
    "    - 예를 들어, 두 개의 문서가 있다면:\n",
    "        ```\n",
    "        문서 1: \"고양이가 나무 위에 있다.\"\n",
    "        문서 2: \"나무 아래에 고양이가 있다.\" \n",
    "        ```\n",
    "    - 이 두 문서를 CountVectorizer로 변환하면 단어 빈도가 포함된 벡터가 생성됩니다:<br>\n",
    "    - `['고양이': 2, '나무': 2, '위에': 1, '아래에': 1, '있다': 2]`\n",
    "### 2) TfidfVectorizer: TF-IDF (Term Frequency-Inverse Document Frequency) 기반 벡터화\n",
    "- 작동 방식: TfidfVectorizer는 단어의 빈도뿐만 아니라, 단어의 중요도를 계산합니다. 여기서는 TF-IDF 값을 사용하여 문서 간 차별성을 강조합니다.<br>\n",
    "- TF (Term Frequency): 단어가 문서에서 얼마나 자주 등장했는지를 나타냅니다.<br>\n",
    "- IDF (Inverse Document Frequency): 단어가 다른 문서에 얼마나 자주 등장하지 않았는지를 나타냅니다. 자주 등장하지 않는 단어는 더 중요한 단어로 간주합니다.<br>\n",
    "- 특징:<br>\n",
    "    - TF-IDF는 문서 전체에서 자주 등장하는 흔한 단어들(예: \"그리고\", \"이다\" 등)의 중요도를 낮추고, 문서에서만 중요한 단어들의 중요도를 높입니다.<br>\n",
    "    - 단순히 빈도가 높은 단어보다 특정 문서에서 더 특징적인 단어에 더 높은 가중치를 부여합니다.<br>\n",
    "- 예시:<br>\n",
    "    - 위의 문서 1과 문서 2에 대해 TfidfVectorizer로 변환하면, 공통 단어들(예: \"있다\", \"고양이\")의 중요도는 낮아지고, 차별적인 단어(예: \"위에\", \"아래에\")의 중요도는 상대적으로 높아집니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f610c",
   "metadata": {},
   "source": [
    "CountVectorizer와 TfidfVectorizer 비교\n",
    "| 특성             | CountVectorizer                                     | TfidfVectorizer                                               |\n",
    "|----------------------|--------------------------------------------------------|-------------------------------------------------------------------|\n",
    "| 기반             | 단어의 단순 빈도                                        | 단어 빈도 + 문서 내에서의 상대적 중요도(TF-IDF)                     |\n",
    "| 단어 빈도 계산    | 문서에서 등장한 단어의 단순한 등장 횟수를 셈            | 단어의 등장 횟수(TF)와 해당 단어가 문서들에서 얼마나 자주 등장하지 않았는지를 함께 고려(IDF) |\n",
    "| 빈번한 단어 처리  | 문서에서 자주 등장하는 단어일수록 높은 가중치를 부여    | 문서에서 흔한 단어는 가중치를 낮추고, 드문 단어는 높은 가중치를 부여   |\n",
    "| 주요 용도        | 단순한 단어 빈도 기반 분석이 필요할 때 사용             | 문서 간 차별적인 단어를 구별할 때 유용                                |\n",
    "| 계산 비용         | 상대적으로 적음                                         | 상대적으로 더 복잡하고 계산 비용이 높음                                |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8723775c",
   "metadata": {},
   "source": [
    "- tokenizer: 형태소를 분석해서 단어를 나누어 주는 역할, 기본은 공백을 기준으로 나눔\n",
    "    - 한국어는 조사가 있기 때문에 공백이 아닌 형태소 분석을 통해서 나눠야 함.\n",
    "    - konlpy의 형태소 분석기를 이용해서 형태소를 나누고 분석\n",
    "- ngram_range(1, 2)\n",
    "    - 단어를 벡터화 할 때 단어의 범위를 지정 (1, 2)는 1-gram, 2-gram\n",
    "    - \"이 영화는 정말 좋다\"\n",
    "    - 1-gram: ['이', '영화는', '정말', '좋다']\n",
    "    - 2-gram: ['이 영화는', '영화는 정말', '정말 좋다']\n",
    "- min_df=4 \n",
    "    - 단어가 등장하는 최소 문서 수를 설정하는 파라미터\n",
    "- max_df=0.9\n",
    "    - 단어가 전체 문서의 90% 이하에서 등장할 때만 벡터화에 포함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d08fb1e",
   "metadata": {},
   "source": [
    "# 한국어 형태소 분석, Countvectorizer/ Tfidfvectorizer 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf07f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=10, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158652f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# countvectorizer + mecab\n",
    "cv_mecab = CountVectorizer(tokenizer=tokenizer, token_pattern=None, ngram_range=(1,2), min_df=4, max_df=0.9)\n",
    "cv_mecab.fit(X_train)\n",
    "cv_mecab_X_train = cv_mecab.transform(X_train)\n",
    "cv_mecab_X_test = cv_mecab.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af45007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c87eb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# countvectorizer + mecab\n",
    "tfidf_mecab = TfidfVectorizer(tokenizer=tokenizer, token_pattern=None, ngram_range=(1,2), min_df=4, max_df=0.9)\n",
    "tfidf_mecab.fit(X_train)\n",
    "tfidf_mecab_X_train = tfidf_mecab.transform(X_train)\n",
    "tfidf_mecab_X_test = tfidf_mecab.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4933d004",
   "metadata": {},
   "source": [
    "# countvectorizer + mecab 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a97f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb1 = MultinomialNB()\n",
    "mnb1.fit(cv_mecab_X_train, y_train)\n",
    "pred1 = mnb1.predict(cv_mecab_X_test)\n",
    "print(classification_report(y_test, pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565bdf42",
   "metadata": {},
   "source": [
    "# TF-IDFvectorizer + mecab 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b78a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb2 = MultinomialNB()\n",
    "mnb2.fit(tfidf_mecab_X_train, y_train)\n",
    "pred2 = mnb2.predict(tfidf_mecab_X_test)\n",
    "print(classification_report(y_test, pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3c0205",
   "metadata": {},
   "source": [
    "# 만들어진 모델 내보내기\n",
    "- 데이터를 분석해서 모델을 만들고 서비스에서 사용하기 위해서는 아래의 사항이 동일해야 한다.\n",
    "    1. 전처리 과정, 결측값, 이상값 처리, 원핫인코딩 등\n",
    "    2. 스케일링, 원핫인코딩, 벡터화 했을 때 정보를 반드시 서비스 코드로 이동\n",
    "    3. 모델도 저장해서 서비스 코드로 이동\n",
    "- joblib을 통해서 직렬화 후 내보내기/불러오기 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2ac055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae489dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec2cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(tokenizer, \"./data/tokenizer.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b333cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(cv_mecab, \"./data/cv_mecab.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65d0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(tfidf_mecab, \"./data/tfidf_mecab.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5981d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(mnb1, \"./data/mnb1_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1191254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(mnb2, \"./data/mnb2_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030c6956",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(text_clean, \"./data/text_clean.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
